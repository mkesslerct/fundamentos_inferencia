# Distribución en el muestreo


## Introducción

Estamos interesados en modelizar un fenómeno que presenta un aspecto aleatorio. Para plantear y contestar preguntas sobre probabilidades de sucesos asociados, buscamos disponer de un modelo para la distribución de los valores de la variable de interés. Iremos construyendo nuestro conocimiento sobre esta distribución al recopilar una muestra de valores, que iremos recogiendo al repetir un experimento.


### Ejemplos {.unnumbered}
- Disponemos de una moneda para tirar a cara o cruz, pero queremos asegurarme de que no está trucada. Para contestar a esta pregunta, planteamos el modelo siguiente: si la variable $X$ recoge el resultado de experimento que consiste en tirar una vez la moneda, puede tomar los valores $c$ (Cara) o $+$ (Cruz) con las probabilidades: $\mathbb{P}[X=c]=p$ y $\mathbb{P}[X=+]=1-p.$ La cantidad $p$ es por lo tanto la probabilidad de que salga cara, y es un parámetro de nuestro modelo. En el caso en que confiamos en que la moneda no está trucada, el parámetro $p$ tomará el valor $1/2$. Para sacar información sobre $p$ y comprobar en particular que la moneda no está trucada, repetiremos un cierto número de veces el experimento.
- Para las próximas elecciones generales, queremos determinar la proporción de gente que tiene intención de ir a votar, es decir queremos estimar la tasa de participación. El censo electoral para España tiene unos 35 millones de personas. Es claramente imposible entrevistar a todas las personas del censo, pero puedo realizar una encuesta para conseguir una muestras de respuestas. Planteamos por lo tanto un modelo simple correspondiente al experimento de escoger al azar a una persona censada: si $X$ es la respuesta a la pregunta "Tiene intención de ir a votar?", puede tomar dos valores 1 ó 0 que codifican las respuestas "Sí" o "No" respectivamente. Llamamos $p$ la tasa de intención de voto, es decir que $\mathbb{P}(X = 1) = p$. Quieremos estimar $p$, y lo haremos repetiendo el experimento de escoger una persona al azar en el censo y preguntarle si tiene intención de ir a votar.
- El índice de audiencias manda en la programación de televisión. Pero ¿cómo saben cuántos espectadores vieron un partido dado o un programa determinado? Claramente, no preguntan a todos los potenciales espectadores. En realidad, una encuesta se realiza de manera automática y continua: una empresa especializada llamada Kantar media, [enlace a su página web](https://www.kantar.com/es), ha escogido al azar unos 6000 hogares  que representan unas 20000 personas de entre un total de más de 40 000 000 espectadores potenciales. En cada uno de estos hogares, instala un aparato llamado ``audímetro'' que registra cuál es el programa que se está viendo en cada momento.
- Queremos conocer la concentración de un determinado producto en una solución. Pensamos que un modelo razonable para la distribución de los valores proporcionados por nuestro aparato de medición sea una distribución normal con media $\mu$ y desviación típica $\sigma$ desconocidas. El centro de esta distribución, es decir $\mu$, será por lo tanto lo más representativo de la concentración que intento determinar.  Para estimar $\mu$, repetiremos la medición varias veces. 

Pero surge una pregunta evidente:

**Pregunta** ¿Cómo sabemos que nuestra estimación es fiable? ¿Por qué limitándose a unas 20000 personas, se puede extropolar el resultado con confianza a una población de decenas de millones? Además está claro que el resultado que obtengo depende de la muestra particular que haya escogido, si hubiera escogido otra muestra, habría obtenido otro resultado. Este hecho se llama la variabilidad muestral.

Para contestar a esta pregunta debemos procurar estudiar la variabilidad muestral, es decir conocer la distribución de los valores que toma una cantidad calculada a partir de una muestra concreta, como la proporción por ejemplo, respecto a todas las muestras que podría extraer. Si esta distribución presenta poca dispersión, tendremos bastante confianza en que el proceso de estimación es poco sensible a la muestra concreta escogida, puesto que la probabilidad de que otra muestra haya arrojado un valor muy distinto será pequeña.

Una manera de realizar este estudio de la variabilidad muestral es a través de simulaciones realizadas con el ordenador. Podemos simular la extracción repetida de muestras de tamaño 20000 de una población. Supongamos por ejemplo, que consideramos la retransmisión en España de la final de la copa del Mundo 2022 que consiguió una cuota de casí 70%, entre los 17000000 espectadores en ese momento, fuente  [noticia en rtve.es](https://www.rtve.es/rtve/20221219/audiencias-gran-final-mundial-catar/2412248.shtml). Supongamos que la proporción de espectadores que vieron la final fue realmente 0. 7. Vamos a definir un vector con 17000000 elementos de los cuales el 70%, es decir 11900000, son "1"s, y el 30%, es decir 5100000, son "0"s. Este vector representará la "población" de todos los espectadores en este momento. Los "1"s representan las personas que vieron la final por la tele.  Escogeremos al azar una muestra de 20000 elementos entre los elementos del vector población y calcularemos la proporción de "1"s en esta muestra. Comprobaremos si está cerca de la proporción de "1"s en la población, que vale 0.7.
```{r}
poblacion = c(rep(1, 11900000), rep(0, 5100000))
set.seed(314159)
p_muestra =  mean(sample(poblacion, 20000, replace = FALSE))
p_muestra
```
Para esta muestra concreta, la proporción muestral de "1"s es muy próxima a la proporción poblacional, por lo que nuestra estimación usando una muestra de "solo" 20000 personas nos da muy buen resultado.

::: {.callout-note appearance="simple"}
## Nota
- En el trozo de código anterior, hemos usado la función `set.seed` que permite fijar la semilla de la secuencia de números pseudoaleatorios que se van a generar. Admite un número como argumento, que podemos escoger como una cantidad fácil de recordar. El fijar la semilla permite reproducir simulaciones aunque impliquen la generación de números aleatorios.
- Para calcular la proporción muestral de "1"s, hemos usado la media muestral, puesto que la suma de los valores en la muestra es igual al número de "1"s que presenta.
:::

Para convencernos de que este buen comportamiento es lo esperable para muestras de este tamaño, vamos a repetir muchas veces (10000 veces por ejemplo), la extracción de una muestra de 20000 personas en la población. Para hacerlo, podríamos repetir el código anterior en un bucle `for`, pero vamos a aprovechar la librería `purrr` del "tidyverse", que permite aplicar una función a los elementos de una lista o de un vector. 

```{r}
library(purrr)
p_muestras = map_dbl(
    1:10000,
    ~ mean(sample(poblacion, 20000, replace = FALSE))
)
head(p_muestras)
```
Podemos ahora representar un histograma de las 10000 proporciones muestrales obtenidas y calcular algún percentil asociado.

```{r}
#| label: fig-histograma-phat
#| fig-cap: Histograma de los valores de la proporción muestral para las 10000 muestras extraidas.
#| warning: false
#| fig-width: 10
#| fig-height: 7
hist(
    p_muestras,
    col = "blue",
    xlab = "Proporción muestral",
    ylab = "Frecuencia",
    main = "",
    xlim = c(0.6, 0.8)
)
```
Comprobamos en el histograma que todas las muestras simuladas llevan a una estimación de la proporción muy próxima a la proporción poblacional. De hecho, `r round(100 * ((fdae <- ecdf(p_muestras))(0.71) - fdae(0.69)), 1)`% de las muestras presentan un error menor de 1 punto respecto al valor poblacional y `r round(100 * ((fdae <- ecdf(p_muestras))(0.705) - fdae(0.695)), 1)`% de las muestras un error menor que medio punto.

En conclusión, este estudio de simulación nos lleva a tener confianza en la precisión de nuestra estimación si extraemos una muestra de 20000 personas para aproximar la proporción en una población de 17000000 personas. En este tema exploraremos esta misma idea de estudiar la "distribución en el muestreo" no solamente a través de simulaciones sino gracias a la obtención de resultados teóricos manipulando probabilidades. 

::: {.callout-note appearance="simple"}
## Inferir
Inferir sobre un parámetro presente en el modelo de distribución de una variable consiste precisamente en sacar información sobre su valor a partir de una muestra de valores de la variable. 

Toda la teoría desarrollada acerca de los sondeos, del control de calidad, del diseño de experimentos, y en realidad, de toda la teoría estadistica se basa de manera esencial en el estudio de la variabilidad muestral de cantidades calculadas a partir de una muestra.
:::

## Muestra aleatoria
Como primer paso en el estudio de la distribución en el muestreo, formalizamos el concepto de muestra aleatoria simple como la variable multidimensional asociada a la repetición de un experimento simple.

::: {#def-mas}
Sea una distribución $f$. Consideramos $n$ variables aleatorias independientes $X_1, X_2, \ldots, X_n$, que tengan cada una la misma distribución $f$. La variable aleatoria multidimensional $(X_1, X_2, \ldots, X_n)$ es una muestra aleatoria simple de $f$.
:::

Decimos que las variables $X_1, X_2, \ldots, X_n$ son independientes e identícamente distribuidas, lo que se abrevia como i.i.d. 
\end{definition}

*Nota:* Por la propiedad de independencia, si $f$ es una función de densidad y $(X_1, X_2, \ldots, X_n)$ es una muestra aleatoria simple de $f$, la función de densidad conjunta de la muestra es el producto de las marginales: 
$$f_{X_1, X_2, \ldots, X_n}(x_1, x_2, \ldots, x_n) = f(x_1)\cdot f(x_2)\cdot \cdots \cdot f(x_n).$$

La situación de modelización más habitual donde consideraremos una muestra aleatoria simple corresponde a la repetición $n$ veces  de manera independiente de un experimento simple al que está asociado una variable $X$ con distribución $f$. Si llamamos $X_1, X_2, \ldots, X_n$ a las variables que recogen los valores de $X$ obtenidos en las $n$ repeticiones, $(X_1, X_2, \ldots, X_n)$ es una muestra aleatoria simple de $f$.

Es el caso del ejemplo descrito en la sección anterior que consiste en tirar $n$ veces una moneda. Si $X_1, X_2, \ldots, X_n$ denotan los valores obtenidos (+ ó c),  $(X_1, X_2, \ldots, X_n)$ es una muestra aleatoria simple de $f$, la distribución de $X$ definida como $\mathbb{P}[X=c]=p$ y $\mathbb{P}[X=+]=1-p.$

En cambio, si consideramos el ejemplo de una encuesta para estimar la tasa de participación, la población de la que se escoge la muestra es finita (unos 35 000 000), y se trata de una extracción sin reemplazo. La probabilidad de que la persona escogida conteste “Sí" va cambiando a medida que vamos entrevistando a gente y depende de las respuestas previas de los encuestados. Por lo tanto, las variables $X_1, X_2, \ldots, X_n$ no son i.i.d. y el vector asociado no forma una muestra aleatoria simple. 

::: {.callout-tip collapse="true"}
### Para saber más 
Si $N_S$ es el número de personas en el censo que tienen intención de ir a votar, y $N$ es el tamaño del censo. Suponiendo que $x_1, x_2, \ldots, x_n$ toman valores 0 ó 1, con la  convención de que $x_i = 1$ si el entrevistado número $i$ declara que tiene intención de ir a votar. Tenemos que 
$$\mathbb{P}(X_i = 1) = \frac {N_S - \sum_{1\leq j< i}x_j} {N - (i - 1)}.$$
:::

## Media de las variables de una muestra.

Sin duda, entre las cantidades más relevantes asociadas a una muestra destaca la media muestral. Empezaremos por lo tanto por estudiar qué podemos decir sobre su distribución muestral, es decir la distribución de los valores que puede tomar respecto a todas las muestras que se podrían extraer. Como primer paso, la obtención de su esperanza y varianza es sencilla y nos proporciona información valiosa sobre su centro y su dispersión:

::: {#prp-distmas}
Si $(X_1, X_2, \ldots, X_n)$ es una muestra aleatoria simple de $f$, que admite tiene esperanza y varianza, consideramos su media $\bar{X}_n =\frac 1 n \sum_{i = 1, \ldots, n} X_i$, se cumple:

- Si $\mu_f$ es la esperanza de la distribución $f$, 
  $$\mathbb{E}(\bar{X}_n)=  \mu_f.$$
- Si $\sigma_f^2$ es la varianza de la distribución $f$, 
  $$Var(\bar{X}_n)=  \sigma_f^2/n.$$
- Si $\varphi_f$ denota la función característica de $f$, es decir $\forall t$, $\varphi_f(t)= \mathbb{E}[e^{itX}]$ donde $X$ es una variable con distribución $f$,
$$ \varphi_{\bar{X}_n}(t)=\mathbb{E}[e^{it\bar{X}_n}]=\left(\varphi_f(t/n)\right)^n.$$ {#eq-caracteristica-suma}
:::

::: {.proof}
La esperanza de $\bar{X}$ se obtiene usando la propiedad de linealidad de la esperanza, mientras que para su varianza, se usa el hecho de que la varianza de la suma de variables independientes es la suma de sus varianzas.
:::

::: {.callout-important}
## Nota
- Es muy destacable que esos resultados son ciertos sea cual sea la distribución $f$: el centro de los valores de la media muestral coincide con el centro de los valores de la distribución $f$ de la cual se muestrea, mientras que su dispersión, medida por su desviación típica, es raiz cuadrada de $n$ más pequeña que la dispersión en la población.
- Si consideramos el experimento de realizar la medición de una cantidad usando un aparato, la variable $X$ denota el valor proporcionado por el aparato, su distribución es $f$. Si el aparato es exacto, el centro de los valores de $f$ coincide con la cantidad que perseguimos determinar. La medición siempre está acompañada de un error, y este error es aleatorio, pero si el aparato está bien calibrado, $\mu_f$ coincide con la cantidad exacta. Si el aparato es preciso, presenta una buena reproducibilidad de las mediciones, es decir que $\sigma_f$ es pequeña. Se puede encontrar en la figura @fig-diana una analogía de la medición con el disparo a una diana. Por la proposición @prp-distmas, deducimos que, si repetimos la medición varias veces y calculamos la media de los valores obtenidos, conseguimos mejorar la precisión (disminuir la dispersión) de nuestro procedimiento. 
:::

![Analogía de la medición con una diana](./figures/dianas.jpg){#fig-diana}

## Varianza muestral
Como medida de la dispersión de una muestra, es útil considerar la varianza muestral que definimos a continuación:

::: {#def-varianzamuestral}
Si $(X_1, X_2, \ldots, X_n)$ es una muestra aleatoria simple de $f$, definimos la varianza muestral $S_n^2$ como
$$ S_n^2 = \frac 1 {n - 1} \sum_{i = 1}^n \left(X_i - \bar{X}_n\right)^2.$$
Es sencillo demostrar la fórmula alternativa para $\bar{S}_n^2$:
$$S_n^2 = \frac n {n - 1} \left(\bar{X^2}_n - (\bar{X}_n)^2\right),$$ 
donde $\overline{X^2}_n= \frac 1 n \sum_{1\leq i \leq n} X_i^2$ es la media de los cuadrados de los valores de la muestra. 
:::
Antes de obtener la distribución de la varianza muestral en el caso de una distribución normal, podemos obtener su esperanza, para cualquier distribución $f$ con varianza finita. 

::: {#prp-espvar}
Si $(X_1, X_2, \ldots, X_n)$ es una muestra aleatoria simple de $f$ con varianza $\sigma_f^2$, 
$$\mathbb{E}[S_n^2] = \sigma_f^2.$$
:::

::: {.proof}
Escribimos 
$$\mathbb{E}[S_n^2] =\frac 1 {n - 1} \sum_{i = 1}^n \mathbb{E}\left[(X_i - \bar{X}_n)^2\right]= \frac 1 {n-1}\sum_{i = 1}^n \mathbb{E}\left[\left(X_i -\mu_f - \frac 1 n\sum_{1\leq j\leq n}(X_j -\mu_f)\right)^2\right].$$ 
Ahora, 
$$\left(X_i -\mu_f - \frac 1 n\sum_{1\leq j\leq n}(X_j -\mu_f)\right)^2 = \left(\frac {n - 1} n (X_i - \mu_f) - \frac 1 n\sum_{1\leq j\leq n, j\neq i}(X_j -\mu_f)\right)^2$$
Al desarrollar este cuadrado nos encontramos con $(\frac {n - 1} n (X_i - \mu_f))^2 + \frac 1 n^2\sum_{1\leq j\leq n, j\neq i}(X_j -\mu_f)^2$ y con productos de la forma $(\frac {n - 1} n (X_i - \mu_f)\frac 1 n(X_j -\mu_f))$, para $j\neq i$. Todos estos últimos productos tienen esperanza nula porque las variables $X_i$ y $X_j$ son independientes.  

Deducimos que 
\begin{align}
\mathbb{E}[S_n^2] &=& \frac 1 {n - 1} \sum_{i = 1}^n \mathbb{E}\left[(\frac {n - 1} n (X_i - \mu_f))^2+ \frac 1 {n^2}\sum_{1\leq j\leq n, j\neq i}(X_j -\mu_f)^2\right]\\ 
 &=& \frac 1 {n - 1} n\left(\frac {(n -1)^2}{n^2}+ \frac {n - 1} {n^2}\right)\sigma_f^2\\ 
 &=& \sigma_f^2.
\end{align}
:::

Deducimos de la @prp-espvar que el centro de los valores de la distribución de la varianza muestral coincide con la varianza de $f$, que llamamos también la varianza "poblacional".

## Distribución de la media y de la varianza muestrales para una m.a.s de una distribución normal.


En las secciones anteriores, hemos caracterizado la esperanza y la varianza de la distribución de los valores de la media muestral $\bar{X}_n$ así como la esperanza de la varianza muestral $S^2_n$. Es destacable el hecho de que estos resultados se obtienen sin hipótesis sobre la forma de la distribución $f$ de $X$. ¿Podemos decir algo más sobre la distribución de estos estadísticos si asumimos un modelo concreto para $f$? En el caso en que hemos modelizado la v.a $X$ por una distribución Normal $\mathcal{N} (\mu,\sigma^2)$ somos capaces de caracterizar con detalles la distribución muestral de $\bar{X}_n$ y de $S^2_n$$, e incluso obtener un resultado sobre su distribución conjunta. La siguiente proposición establecer resultados de gran importancia para la teoría de la inferencia.

::: {#prp-distxbar}
Consideramos una muestra aleatoria simple de una distribución normal $\mathcal{N}(\mu,\sigma^2)$, $\bar{X}_n$ es su media muestral y $S^2_n$ la varianza muestral, se cumple
1. $\bar{X}_n$ y $S^2_n$ son dos v.a. independientes. 
2. 
$$\bar{X}_n\sim \mathcal{N}(\mu,\frac {\sigma^2} n),$$
o, de manera equivalente,
$$\frac{\bar{X}_n-\mu} {\sigma/\sqrt{n}} \sim \mathcal{N}(0,1).$$
3. $(n - 1)S_n^2/sigma^2$ sigue una ji-cuadrado con $n - 1$ grados de libertad.
:::

::: {.proof}

:::
Como ejemplo, consideremos un aparato de medición que  proporciona valores que se distribuyen según una Normal, con una media de 120 y una desviación típica de 12. Por la propiedad de la distribución Normal, el 95\% de los valores están entre $\mu-2\sigma$ y $\mu-2\sigma$, es decir entre 96 y 144. En cambio, si repito 9 veces la medición y proporciono la media de estas nueve mediciones, el 95\% de los valores que obtendría con este procedimiento se encontrarían entre  $\mu-2\sigma/\sqrt{n}$ y $\mu-2\sigma/\sqrt{n}$, es decir entre 112 y 128, lo que implica una precisión mucho mayor.

En una subsección posterior, veremos que este resultado es válido asíntoticamente (cuando $n$ tiende hacia $+\infty$), para una clase muy grande de distribuciones $f$ de $X$.

## Varianza muestral
